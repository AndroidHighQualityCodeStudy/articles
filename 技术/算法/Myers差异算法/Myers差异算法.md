<a name="index">**目录**</a>

- <a href="#ch1">**1 解决的问题**</a>
- <a href="#ch2">**2 Myers贪心策略**</a>
    * <a href="#ch2.1">2.1 编辑图</a>
    * <a href="#ch2.2">2.2 公共轨迹 snake 和轨迹偏移 k</a>
    * <a href="#ch2.3">2.3 两条引理</a>
    * <a href="#ch2.4">2.4 具体实现</a>

<br>
<br>

### <a name="ch1">1 解决的问题</a><a style="float:right;text-decoration:none;" href="#index">[Top]</a>

Myers差异算法（以下简称 Myers算法）源于解决两个字符串的最长公共子序列问题（LCS）或编辑距离问题（SES）。LCS 和 SES 从本质上讲是等价问题：

- 假设字符串 A 和 B，如果找到了它们的一个最长公共子序列 C，那么从 A 转换到 B，就相当于 `在 A 上删除 A - (A ∩ C)` 然后 `插入 B - (B ∩ C)`，而执行这两步就相当于解最短编辑距离问题。
- 若找到了 A 转换到 B 的最短编辑距离，那么除去需要从 A 中删除和添加的字符以外，剩下的字符都是 A 和 B 都有且相对顺序一致且长度最长的字符集，即最长公共子序列。

基于以上的认识，如果给定一种操作即同时遍历 A 和 B，`x` 表示 A 的当前索引，`y` 表示 B 的当前索引；同时给定三种执行命令：

- `deleteA`：表示删除 A 中当前索引位置的字符。
- `insertB`：表示插入 B 中当前索引位置的字符。
- `skip`：表示同时跳过 A 和 B 中当前索引位置的字符，如果 `A[x] == B[y]` 则执行此命令。

现假设有一段命令序列形如：`Seq = [deleteA, deleteA, insertB, skip, skip, ..., insertB, skip, deleteA, skip]`。且执行 Seq 后，`skip` 跳过过的字符组合过来就是一段 LCS，而 `deleteA` 和 `insertB` 的数量就是 A 到 B 的最短编辑距离长度，那么我们说 Seq 是一个 LCS 和 SES 的可行解，如果我们能找到一种算法，该算法可以返回一个可行的 Seq，那么我们说这个算法是 LCS 和 SES 可行的。

Myers 算法就是一个 LCS 和 SES 可行的算法，其时间复杂度为 `O(ND)`，其中 N 表示字符串 A 和 B 的规模（通常情况下两者的长度差异很小，可以归一为 N），D 表示 A 和 B 的最小差异长度（即最短编辑距离长度）。而常规的动态规划算法解 LCS 问题的时间复杂度为 `O(N²)`，一些改进型算法可以优化到 `O(NlogN)`。可以看到，Myers 算法严格优于常规动态规划算法，当 `D << logN` 的时候也要优于改进型算法，同时 Myers 算法的空间改进版本可以优化到 `O(N)`，在内存空间受限的应用场景具有明显的优势。

<br>
<br>

### <a name="ch2">2 Myers贪心策略</a><a style="float:right;text-decoration:none;" href="#index">[Top]</a>

Myers 算法的执行过程与上一节描述的方法比较类似：同步遍历两个字符串，只不过并不是简单按照索引顺序进行遍历，而是先对问题进行一些形式化处理，并根据形式化的规则来进行遍历。我们先看看 Myers 算法对问题的形式化处理。

#### <a name="ch2.1">2.1 编辑图</a>

**编辑图** 是一个二维坐标图，x 轴表示为源字符串 A，A 中的每个字符索引与 x 坐标点一一对应；y 轴表示为目的字符串 B，B 中的每个字符索引与 y 坐标点一一对应。

一条 **path（路径）** 描述为从原点 (0, 0) 开始或沿着 x 正方向或沿着 y 正方向或同时沿着 x 和 y 对角线方向移动的轨迹。每往右走一步，x + 1，表示删除 A 中当前字符；每往下走一步，y + 1，表示插入 B 中当前字符；每往对角线方向走一步，x + 1 且 y + 1，表示 `A[x] == B[y]` ，跳过当前 A 和 B 的坐标值。

标记 **D-path** 为在一个给定编辑图中需要经过 D 次编辑（删除或插入）操作后的 path。

把 path 的轨迹用坐标点分别列出来，就形成了一条 **trace（追踪）**：(x1, y1) (x2, y2) ... (xL, yL)，其中 L 为 path 的长度。算法结束后将得到一条从 (0, 0) 到 (N, M) 的 trace，其中 N 为 A 的长度，M 为 B 的长度。

将形成 path 的操作列出来就得到一段 **edit script（编辑代码）**。编辑代码包括两条命令：

- *`xD`*：删除 A 中索引位置为 x 的字符，即 `A[x]`。
- *`xIb1,b2,...,bt`*：在 `A[x]` 之后插入字符序列 b1,b2,...,bt。

以下就是一个编辑图的例子（来自 Myers 的论文）：

![Edit Graph](images/edit_graph.png "Edit Graph")


#### <a name="ch2.2">2.2 公共轨迹 snake 和轨迹偏移 k</a>

一条 **snake** 就是编辑图中的一条对角边，表示的是 A 和 B 的当前字符相等，不需要进行编辑，抑或是公共子序列中的一个公共字符，所以我将 snake 称之为 **公共轨迹**。

一条 snake 所在的直线在编辑图中如果用线性方程表示即为：`y = x - k`。因为每次都同时往 x 和 y 方向走一步，所以不同的 snake 都有相同的斜率为 1，其唯一的不同在于其所在直线以 y 轴（或 x 轴）为基线在 x 轴（或 y 轴）上的偏移位置，而 k 就是这个偏移，归一化为 `k = x - y`。所以这里我称之为 **轨迹偏移 k**。

不难推断，每个 k 都是由两个特定的前向编辑操作之后导出的：要么是从 k + 1 因为插入操作向下变为 k；要么是从 k - 1 因为删除操作往右变为 k。

接下来引出两条关键的引理。


#### <a name="ch2.3">2.3 两条引理</a>

- **引理 1：在一条 D-path 中，最后一条 snake 的轨迹偏移 k ∈ { -D, -D+2, ..., D }**。

引理 1 给出了末端轨迹偏移 k 与编辑距离 D 之间的关系：**编辑距离 D 与 末端 k 有相同的奇偶性**。

该定理容易用数学归纳法证明：首先，0-path 表示 A 和 B 完全等价，不用编辑，只有一条 snake，且 `x == y`，即 `k == 0`；假设 D-path 满足定理要求，对于 (D+1)-path，D-path 是其子问题，且只可能由 D-path 问题经过一系列 snake 之后要么执行删除（往右，k-1），要么执行插入（往下，k+1），然后又经过一系列 snake 完成。于是 (D+1)-path 满足 `k ∈ { (-D)±1, (-D+2)±1, ..., (D)±1 } = { -(D+1), -(D+1)+2, ..., (D+1) }`，得证！


- **引理 2：一个末端轨迹偏移为 k 的 D-path 问题，可以分解为一个末端偏移轨迹为 k-1 的 (D-1)-path 问题和一个插入操作之后跟若干段尽可能长的连续的 snake；或者分解为一个末端偏移轨迹为 k+1 的 (D-1)-path 问题和一个删除操作之后跟若干段尽可能长的连续的 snake。**

引理 2 实际上就是说明 **D-path 问题具有最优子结构性质**。具体来说，D 和 k 决定了问题的规模；引理中描述的 `在一个编辑（删除\插入）操作之后跟若干段尽可能长的连续的 snake` 说明了我们可以考虑在子问题中采用贪心策略。即，在每编辑一次之后，尽可能地把当前位置之后所有连续的相等的字符都跳过，这样做的目的就是尽可能地把问题的规模缩小到极致，这是一种非形式化的证明。


#### <a name="ch2.4">2.4 具体实现</a>

根据上一节的两个引理，我们大致可以按照如下的方法来求解一个差异问题：

首先，如果给定一个差异问题，那么其 D 和末端 k 就是确定的，那么如果将问题分解为子问题，那么每个子问题都一一对应一个 D 和末端 k，且 `子问题 D < 父问题 D`，根据引理 1 可知 `子问题末端 k < 父问题末端 k`。

其次，给定一个差异问题，那么也就确定了该问题 D 和 k 的范围，比如 D-path 问题，`D ∈ [0, M+N]`，`D == 0` 表示 A 和 B 等价，`D == M+N` 表示 A 和 B 没有任何公共字符。

所以，反过来如果对于 D 和末端 k 范围内的每一个值都能计算出最后一个 snake 最远能到达的距离，即 trace 最终能到达的坐标点 (xL, yL)，那么也就确定了该 D 和末端 k 对应的子问题，如果 (xL, yL) == (N, M)，就说明该子问题就是原问题，而此时的 D 和末端 k 就是原问题的解。

大致的流程如下（源于 Myers 的论文）：

```
For D ← 0 to M+N Do
    For k ← −D to D in steps of 2 Do
        计算出 D-path 在末端 k 能到达的最终坐标点 endpoint
        If endpoint == (N,M) Then
            The D-path is an optimal solution.
            Stop
```


我们可以用一个数组 V 来存放上一个子问题（即 (D-1)-path 问题）的相关解，设 `V[k] == x`，那么就相当于数组 V 同时存放了每个子问题的 x,y,k 三个值，即 `一个末端轨迹偏移为 k 的 D-path 问题其 trace 最远能到达 (x, y)`，伪代码如下（源自 Myers 论文）：

```
    Constant MAX ∈ [0,M+N]
    Var V: Array [− MAX .. MAX] of Integer

1.  V[1] ← 0
2.  For D ← 0 to MAX Do
3.      For k ← −D to D in steps of 2 Do
4.          If k = −D or k ≠ D and V[k − 1] < V[k + 1] Then
5.              x ← V[k + 1]
6.          Else
7.              x ← V[k − 1]+1
8.          y ← x − k
9.          While x < N and y < M and a x + 1 = by + 1 Do (x,y) ← (x+1,y+1)
10.         V[k] ← x
11.         If x ≥ N and y ≥ M Then
12.             Length of an SES is D
13.             Stop
14. Length of an SES is greater than MAX
```


注意到代码第 3 行的循环，每次循环中，k 的奇偶性都是确定的，且相邻两次循环的 k 值的奇偶性都不同，即 k 与 k+1 和 k-1 的奇偶性正好相反，又因为 D-path 的计算只与 (D-1)-path 相关，所以上一轮计算出来的 V 的值正好可以被当前轮循环利用到且不用担心脏数据。同时也说明该算法既是一种贪心算法也是一种动态规划算法。

现在来说明代码第 4 到第 8 行，这一段代码用来确定 `V[k]` 即 `x` 的值。也可以说根据末端 k 确定当前子问题的末端 snake 的起始坐标。具体来说：

- 如果 k == -D，那么前一个子问题 (D-1)-path 的末端 k 可能为 k+1 == -D+1 或者 k-1 == -D-1，而根据引理 1，(D-1)-path 的 k ∈ { -(D-1), -(D-1)+2, ..., (D-1) }，所以 (D-1)-path 的 k 值不可能为 -D-1，即当前问题只能由 (D-1)-path 从末端轨迹偏移 k+1 插入字符后进行转换。所以，当前问题的 x 坐标与子问题 (D-1)-path 的 x 坐标相等，而子问题 (D-1)-path 的 x 坐标保存在 `V[k+1]` 中。















































